# OLLAMA

The AI Platform


## Configuration

Configure from Home Assistant integration. It has problems or lag time when Ollama model is set from the container. 

Use the `qwen3:1.7b` if there is **NO** GPU or on a lower power computer. Other models were taking too long.